This is being exposed as a service for a single client, but all along
it was intended as a general feature of certain storage adapters, and indeed
was one of the founding dream-features of kiss-rdb.

The idea is that since kiss-rdb uses "plain old" text files, and since
plain old text files are typically stored in VCS (in our world); we can
use data from the VCS to generate interesting reports about the entities
in a collection; specifically an "audit trail" (or "edit history") of
a particular entity.


# Requirements & Other Design Objectives

Here's different dimensional vectors (beyond just the cut-and-dry objectives
we're imagining in our heads that don't need explaining here):

- Progressivity: We want to be able to traverse-index a large collection
  in arbitrary, multiple passes. If something fails mid-traversal, we want
  to be able to pick up where we left off, not having to re-do the same work.
  Optionally we want to be able to keep our "data warehouse" in the (imagine)
  sqlite database and only update it with new changes as desired. (This
  concern is more one of the client and not us, in the frontier use-case.)

- Tooling: we want the indexing to be exposed to the command-line but
  absolutely not be command-line only or even command-line centric.

- Resources and Performance over KISS vs. not KISS: The low end: Not writing
  tempfiles as much as possible: For the client's use case, we're going to be
  indexing a "large" collection of "documents" each of which is derived from
  typically several entities. We will be working a lot with diffs (at first
  context diffs, of the kind `git` presents). We would really (really) love
  it if we did not have to write any tempfiles to disk, for example to see
  what change a patch would make to a file. Lots of intermediate writes to
  disk will involve IO and having to handle cleanup, which will have a
  performance cost as well as a code cost.

- Resources and Performance over KISS vs. not KISS: The high end: On the
  other hand, if we do everyting in memory (avoiding reading to/writing from
  disk), we would fill up the memory pretty quickly for large collections;
  so it would be just bad style to use memory in a way that doesn't scale
  up to large collections of entities. It should be "stream friendly" so that
  it scales out in linear time to larger and larger collections.



# Towards a rough draft of the theoretical algorithm:

`git log` goes in reverse chronological order, from now back in time to
the beginning of the tracked content (or as far as is indicated by options).

We think we read somewhere that this isn't just a surface UI decision; that
it's something about how git's object-database works.

There was a full two days were we imagined we would take the output of this:

```bash
git log --patch path/to/your/eno-collection
```

and parse it commit-by-commit streamingly to generate a full audit log for
a full collection (going back in time starting from the present, going back
to as far as you want it to, stopping on demand)

There's a couple issues with this:

- This isn't friendly if you just want the audit trail for a single entity
- As it turns out, this whole approach is hard (see "Appendix A" below)

Thank *_god_* we skimmed over the manpage for `git-log` and saw the
'-L' option. It was about to get a lot more complicated without itâ€¦

We tried prototyping our thing with this just now and it seemed to work okay..


# A ROUGH DRAFT OF THE THEORETICAL ALGORITHM

git log --follow -L'^/^# entity: VGZ/,/^# entity: /:pho-doc/notecards/entities/V/G.eno' --format=tformat: -- pho-doc/notecards/entities/V/G.eno

if this fails because thing thing, you can omit the second line indicator,
assuming it failed because the entity was physically last in the file.

git log --follow -L'^/^# entity: VGZ/,:pho-doc/notecards/entities/V/G.eno' -- pho-doc/notecards/entities/V/G.eno

if neither of these produced a stream of output, behavior is undefined

Note we could have specified a `--format=tformat:foo` but we intentionally
didn't both for KISS and because the output we get by default is good.


A typical output will start like this:

```
commit 579429961ba479bae07b11293d8e7687f08168c4
Author: Katherine Johson <hidden.figure@nasa.gov>
Date:   Sun Feb 21 22:42:52 2021 -0500

    convert from old format to eno

diff --git a/pho-doc/notecards/entities/V/G.eno b/pho-doc/notecards/entities/V/G.eno
--- a/pho-doc/notecards/entities/V/G.eno
+++ b/pho-doc/notecards/entities/V/G.eno
@@ -1,47 +1,55 @@
+# entity: VGZ: attributes
+hierarchical_container_type: document
+heading: (really rough notes about Gauss)
+-- body
 Love this [Khan's adademy article][1]; It's my dream as a boy and as a man.

 Synonyms for a distribution of values clustering around a

```

So:

- parse the "commit" line (the SHA), because we will use it in our
  representation of the commit in our output
- "Author:" same
- "Date:" same (why don't we go ahead and etc)

- Parse the body lines of the commit explanation (what's that called),
  all of them for now

- Parse but disregard the patch header line about which file
- same '---'
- same '+++'

- Now, at '@@', using our excellent new diff hunk parsing function

- At the end of it, expect another "commit [SHA]" line or the end up input.


Each of these such runs of lines will produce one "EDIT" structure
Note that for all imaginable cases, the last "EDIT" structure produced
will be actually a "CREATE" instead of an "EDIT". We should address this
somehow, probably by detecting when the hunk is all creates (with no
context) and then asserting it is the last chunk in the upstrea stream
(last chunk = first commit for the entity)

Do something about the any final line of context that belongs to the
next entity in each of the chunks, when it's that way.


# About the Product

The things to notice about our output:

- SHA
- datetime
- Author (string)
- Full Commit Message
- One Single Hunk

(in a stream)

By virtue of the `git-log -L` option, the diffs we get from upstream are
always a single hunk that comprises the full length of the entity-in-file.

(EDIT: confirm the above)


# Missing Features and Future Directions

For this to be a true audit log, it would granularize along the lines of
the attributes of the entity:

```

  changes_in_attribute_constituency:
     attributes_in_before_not_in_after: (..)
     attributes_in_after_not_in_before: (..)

  changes_in_attribute_value:
      {'attr_1': [diff],
       'attr_2': [diff]
      }
```

This is the direction we would like to take it, but it will require more
work and is out of scope for our current frontier case.



# Appendix A: why it's hard

Applying a patch (lines) to a file (lines) without writing to the filesystem
is hard. `difflib` in the standard library can do it with its `ndiff` format
but it would take work and tinkering and testing to get it to work with
git-generated context diffs.

There is a pip library called `patch` but we had some issues with it
(one of which was why the hell is there a package called `patch-python`
in my environemnt, one that seems to do almost nothing and takes up the
name `patch`). Also we would like to avoid adding such a dependency if
possible.

Another issue is that we have to map diffs-in-files to diffs-in-entity.
We have done it elsewhere and it's not pretty.



# (document-meta)

- #born
