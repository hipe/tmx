# towards an expression adapter for formal entity sets in arbitrary domains :[#029]


## introduction

towards implementing criteria, we are taking the long view..


## the objective is..

..for the human user to express in a subset of her natural language (in
today's case "english") a "criteria" that can be interpreted
unambiguously into internal objects that exhibit the necessary agency
to effect "the criteria".

as opposed to trying to be able to interpret many different surface
expressions for the same deep structure, we will try to limit the
modeling of supported variants. our primary objective is that the
surface expressions read naturally, not that as many natural surface
expressions as possible are able to be intrepreted.

so for exmaple we might be able to interpet:

   "$10 or cheaper" -OR-
   "$10 or less" -OR-
   "$10 or under"

but we will not be modeling grammars that can support all of these
together. the DSL designer must chose which phenomenon she will support.
we will refer to this rubric as "no synonyms".

the codename for this vapor-ware natural langauge subset is currently
"sudocode".




## (low-level tactical design objectives)

let's never allow that the client produce platform modules or classes to
associate its domain with NLP. (we are doing this both as an experiment
and for the selfish reason that it will make testing easier.)

i.e imagine that our meta-DSL is a "prototype-based" and not
"class-based" object oriented language.




## introduction to model components (interspersed with pseudocode)

  • the "domain adapter" is the all-encompasing top-level structure
    that associates certain patterns of phenomena in natural langauge
    with business strucures (specifically "the model") in the client
    application.

  • the "domain adapter" will model strategies for interpreting
    (and maybe one day expressing) both specific entities and formal
    entity sets from streams of tokenized strings (representing the
    would-be natural-languge-esque input).

  • "formal entity sets" is an ad-hoc concept we model here to represent
    abstract sets of entities for use in modeling queries ("criteria").
    for example, if our domain includes the counting numbers, we might
    want that the expression "N > 5" models the "formal entity set" of
    all counting numbers greater than 5.

  • "boolean trees" (to be expanded upon below) will be specfic kinds
    of formal entity sets: "N > 5 and N < 7" is a boolean tree
    (an "and" tree) that "ands together" two other formal entity sets.
    to "AND-together" (or "OR-together") two FES's, if they are not
    subsets of the same entity model (in this case, the counting numbers),
    they will always filter all values.

  • currently we will assume that the front client's specific natural
    language is "english" (of some particular variety).
    *HOWEVER* we will attept not to bake this assumption in too deeply.
    this will be difficult to do while still meeting our objective at
    first go, so at this pass it is a non-priority "design vector".

  • the "domain adapter" at its level will consist of nothing more
    than a list of "model adapters".

  • a "model adapter" will associate one (and for now only one)
    "lemma"-like noun phrase with the application's particular model
    (class / "silo" (see [br]). representing and resolving the
    particular platform class in the particular client application is
    beyond our immediate scope.

  • a "model adapter" will have zero or more "association adapters".
    currently, the idea of an "association" (as seen in ORM's) is not
    built directly into the adjunct framework library [br]. however,
    because this is such a strong (and important) idiom in the broader
    universe, we will proced as if the adjunct framework does recognize
    such structures formally.

  • at this level, our side of things will not be concerned with whether
    the application model models a particular phenomenon as variously
    a model (class) or a property (think "ivar" or "attribute").

    the boundary bewtween model and attribute is plastic, and it is
    space that per model per application we don't want to get caught
    up in. our "gordian knot" solution is essentially to say that
    everything is a model, and there are no properties (MAYBE)..

    we may refer colloquially to models that exist in NLP adapters but
    not as model classes in the application as "virtual models". more below.

  • the "association adapter" exists primarily to model exactly one
    verb lemma. frequently (and in our particular assumed natural
    language) this lemma will be the verb "has" (more accurately "to have").
    however we stipulate the requirement that this not necessarily
    be the case. imagine a model adapter with the noun "item" and
    another model "price". we may want to be able to interpret a
    criteria like:

        "the item costs between $5 and $10"

    in such an example, we would probably want to model the association
    between "item" and "price" with the verb "cost". alternately
    (and more verbosely) we could have used the fallback verb "has":

        "the item has a price between $5 and $10"

    for one thing, we want to be able to model the former case if we
    want to; and for another thing, we recommend to ourselves that
    currently we try not to support the interpretation of both.

  • experimentally, we are going to say that "association adapters"
    exist *under* the target (not source) model (or object noun phrase,
    not subject noun phrase if you prefer). this may change. but
    consider:

  • it will also be "association adapers" that model this phenomenon of
    adjectives used as sort of complementary "unit adjectives" (in EN):

        "a thing that is ten feet tall"
        "..three miles wide"
        "..12 years old"
        "..4 minutes long"
        "deep", "overweight", "accross" etc

    because we suspect it will "just work" (hopefully), we don't want
    to have to re-model such rules redundantly for each association.
    rather we suspect that such adjective-esque suffixes are best
    modeled inside the associated (and not associating) model.

  • the above phenomenon of "unit adjectives" will also need to model
    transformations when used in formal entity sets:

        "a thing that is 30 years old"
        "a thing that is younger than 30"
        "a thing that is older than 30"
        "a thing that is 30 years old or younger"
        "a thing that is 30 or younger" (more difficult but not
          impossible to interpret)
        "a thing that is between 45 and 55 years old"

    the pattern seems to be that you need a pair of adjectives:

        (distance in the lateral dimention)     "narrow"  <-> "wide"
        (distance in the vertical dimension)    "short"   <-> "tall"
        (distance in the [this] dimension)      "shallow" <-> "deep"
        (distance in the assumed dimension)     "short"   <-> "long"
        (duration (i.e distance) of time)       [ same as above ]
        (age)                                   "young"   <-> "old"
        (time of day (i.e point in time))       "soon"    <-> "late"
        (weight)                                "light"   <-> "heavy"
        (cost ..!)                              "cheap"   <-> [ "more than" ]

    often but not always a term is used as an "endcap" adjunct to
    an explicitly expressed unit. in all seen cases below, it is the
    right-hand-side word of the word pairs above that is used for
    such "endcaps". and note the null cases included too:

        "3 miles wide"  ("mile" is the unit, "wide" is the endcap)
        "3 feet tall"  (etc)
        "2.5 meters deep"  (etc)
        "3 feet long" (etc)
        "3 hours long"
        "30 years old"
        !"3PM late"
        !"10 pounds heavy"

    for our own sanity we will say that that the *model* adapter can
    have zero or two of these "adjectives", and a boolean
    indicating whether or not we express and interpret "endcaps"

  • it's worth mentioning here explicitly: the goal of this library
    is to be able to support the interpretation of construtions like
    the above through the modeling facilities the library cosists of.
    the value-prop of the library is decidedly *not* that it provides
    support for the above constructions out of the box; that is left
    for the designer to implement. (however, constructions like the
    above will be used throughout the tests and will be intended to
    serve as pedagogic examples).

  • "formal entity set nonterminals" will be perhaps the workhorse
    component of this phase of this project. they will perhaps exist
    many-to-one under a model adapter. they are what translates
    "phrasal noun modifiers" into platform-specific executable
    components. this is all we think we know for now..


## the frontier feature

the thing we plan to have most fun with (and expect to have the most
challenge with) is a feature we are calling "antecedent-aware parsing":

for now, the pseudocode is something like this:

    assume every expression we parse follows the form:

        expression ::= definite-noun verb-phrase

        verb-phrase ::= verb formal-set

    example:

        "the item costs at most $10"

    any time we hit one of our hard-coded boolean conjunctive tokens
    "and" or "or", do this:

    with the tokenizer *at* the (assumed) token that came after the
    conjunctive keyword,

    from the recentmost element of the parse tree, run the input
    stream against relevent adapter, then *adapter collection* of
    that node. the first one that accepts input wins.

so for example:

    "the thing is 6 feet wide or 10 feet tall"
    "the thing is 6 or 7 feet wide"
    "the thing has color 'red' or 'green' and is available"

in the first example, after parsing "6 feet wide", the "width" adpater
(with tokens of lookahead) says "'10'? yes. 'feet'? yes. 'tall'?
no." so we fall back from this particular adapter to the collection of
adapters. the "height" adapter eventually finds and parses the rest of
the input, putting its parsed expression into an '-or-' tree of
phrasal noun modifiers. (we implement this specifically in spec 04:
"verb sharing".)

in the second example, the '-or-' tree that is built comes from the
model adapter: after parsing '6', the width (and height (and etc)) model
adapters are OK with parsing '7', then 'feet'. only when 'tall' is
parsed does the height adapter declare itself the winner.
( in spec 03: "delayed tail" )

in the third example, there is an '-and-' tree that has an '-or-' tree
as one of its two nodes. (in "synthesis")

we will probably use all of these examples in the tests to build this.

note that you cannot "go back":

    !"the thing has color 'red' and is available or 'green'"

the "or 'green'" part will have no found meaning because its context is
lost: when trying every element of the parse tree at that point, none
will recognize what 'green' is

    (at that point, you would have:

      "definite-noun-phrase" "model-verb-phrase"

    and the model verb phrase would belong to the "availability" model
    which would try parsing "or 'green", fail, defer up to the
    definite noun phrase, which would try to parse it and fail. done.
...
