# tmx doc-test

## objective & scope

the subject sidesystem is an experimental for-fun tool that generates
tests from comments. it is inspired by python's "doc-test" tool
(although we have held off from looking at that project beyond a cursory
glance in the interest of coming up with ideas in a vacuum and only
afterwards comparing them to whatever else is out there (and then
variously kicking ourselves and lauding ourselves as appropriate)).


### synopsis

if your "asset document" contains something like this:

    # this singleton method
    # makes a string from two strings:
    #
    #     MyLib.join( 'foo', 'bar' )  # => "foo AND bar"

    (your code here)

    # it can produce an array from such a string:
    #
    #     MyLib.split( 'foo AND bar' )  # => %w( foo bar )

    (more code here, etc)

the subject sidesystem can produce something like this:

    it "makes a string from two strings" do
      MyLib.join( 'foo', 'bar' ).should eql "foo AND bar"
    end

    it "can produce an array from such a string" do
      MyLib.split( 'foo AND bar' ).should eql %w( foo bar )
    end


see more in the "overview" section below.



### current limitations

because both a) this is largely a proof-of-concept and b) to do this
"right" is outside our current scope of interest for this platform,
this entire project is at its essence a hack: we "parse" code files and
test files in this project, but we do *not* do so the "right" way, so edge
cases will certainly exist where the subject sidesystem will fail.
(this is discussed further in [#019] current limitations in parsing.)



### general limitations

we do not proffer that the sort of tests generated by this sidesystem
should serve as a replacement for unit tests. what makes good unit tests
and what makes good documentation examples are largely a different set
of characteristics (depending of course on whom you ask):

  • perhaps unit tests should take small steps that are good for regression.
    maybe they should even be [#sl-129] "three rules" compliant.

  • perhaps good documentation examples should focus on giving a
    high-level overview of key features.

(but note that as we write this we are in the middle of a rewrite that
is meant to make these two worlds coalesce somewhat..)




## a deeper understanding of the "syntax"

to understand how to get the subject sidesystem to do exactly what you
want (to the extent that that is possible), it may be useful to
understand how it parses asset documents and turns them into test
documents.

at the coarsest level, the subject sidesystem parses the input (which it
sees as a line stream, but which is usually a file (an "asset document"))
into "blocks": comment blocks and static blocks. see [#020] "what are
comment blocks?" for more on this particular part of it.

then, we try to parse every comment block into test-related expressions
by first breaking the comment block into "runs" of associated lines.
there are "discussion runs" and "code runs". the former is freeform
natural language, and the latter is example code that can (sometimes) be
turned into tests. for more about this, see [#021] "what are runs?".

these "runs" (that is, discussion runs in tandem with code runs) can
then be turned into "items" like examples (or experimentally shared
setup methods) which ultimately can contribute to producing test code.
for detail on the logic behind this, see [#024] "what are items?".

but we leverage the most power from the subject sidesystem by pointing
it at existing test files, which we call "synchronization"..




## experimental cool new feature 1: synchronization

(EDIT)




## experimental cool new feature 2: reverse synchronization

(EDIT)

_
