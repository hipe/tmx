# PREFACE

(this document was basically rough notes, then we prototyped the thing
and now a lot of the algorithm doesn't match the theory here but we
decided we wanted to just lock it down for posterity before editing it
down..)



# Synopsis

Generate descriptive blurbs like this:

```
Created on March, 2019. Small edits twice in March and once in April.
A large edit in May. In 2020, two small edits in February, eight small
edits in June-August. One large edit in February 2021.
```


# Objective & Scope

The near-term objective of this is a working prototype demonstrating
TMX notebook integrating with VCS to produce a "derivative" feature
that feels similar to one found in popular wiki's (MediaWiki (Wikipedia))
and CMS's (wordpress, probably).

That feature (which we'll call a "feature-space") is "page history".
(We'll use this particular term for our take on this feature-space,
appropriating [it][1] from nearest-popular-neighbor MediaWiki.)


# A popular vendor take on the feature-space

We decompose this feature-space into specific feature-details that are
hypothetically fungible from one to another CMS-like. We'll intermix
MediaWiki concepts (e.g., "username") with the corresponding terms from
our system ("author" because pelican) without necessarily indicating which
is which (when there's a difference); but just be aware there is only one
"correct" term for our system. So, from Wikipedia's description of this
one part of itself:

> The page history contains a list of the page's previous revisions, including
  the date and time [â€¦] of each edit, the username or IP address of the user
  who made the change, and an optional edit summary that briefly describes
  or explains the change.

So in MediaWiki every "revision" has:

- "date and time" (so datetime) (surface-presented in UTC by default)
- "username or IP" (author) who made the change
- the change as a diff or equivalent which can be used to show paragraph-,
  line- or even word-level changes (probably).
- an optional "edit summary" that briefly describes or explains the change.



# Our take on the feature-space

For our real-world use-case, we're targeting a much simplifed subset of the
above feature-set. To break down our objective (stated at the top) further,
it's twofold:

1) Demonstrate the novelty, "power" and viability of VCS-derived features
   like this
2) Just give the reader a relative sense of how long the document has existed
   and how much "action" it's seen

We do not have multiple authors to start (although if we did want to treat
this, we would try to derive it also from VCS) so at first authorship
_will have no surface treatment at all_. (That is, there will be no Author
field ("By Korra") visible on the page in our One Theme.)

(But as we write this, we like the idea of a "default author" in settings,
one who doesn't get visual representation, but we would show those authors
(if any) when they are not the default author. But that brings us outside
of this scope.)

We're not interested in showing actual diffs at this point, because that
would take us out of the KISS scope of using an SSG. (Pelican does have
a "view source" thing we think, but, that's out of scope for now.)

So having eliminated "author" and "diff" from the running, (and we'll skip
"edit summary" too since it's not very useful without being next to
"diff"), what we have is:

Many edits with, for each edit:

  - datetime
  - verb (always CREATE at the beginning, and EDIT ever after)
  - some numeric derivative of the diff; like line-action SUM (sum of number
    of lines removed and number of lines added; as a rough scalar measure of
    the amount it was edited. We'll call this the "change amount" and revisit
    it below.)



# What are HCS's?

What we're calling a "hierarchical component system" here is actually found
everywhere: books have chapters have pages, months have weeks have days,
cities have neighborhoods have streets have buildings, etc.

We can see HCS's in human-made concrete things (cars have transmission
systems have ???) as well human-made abstract things (the US Government has
the exective branch which has the Department of Justice, which has something
like 36 agencies). Also it seems that HCS's are useful for modeling,
understanding and interacting with natural/biological phenomena (mammals
have digestive systems which have particular organs etc), or physical
phenomena (planets have atomosphere.., a lever has a fulcrum..)

Probably this idea (abstract and essential as it is) has lots of formal
treatment elsewhere and we're not covering any new ground here. But we
needed a term for it *now*. (For the record, the general idea was put in to
our head as a _thing_ by Robert M. Pirsig in
_Zen and the Art of Motorcycle Maintenence_.)



# Approaching a domain language for summarizing with HCS's

HCS's have particular properties that will be useful to exploit for
summarization. Here we describe these properties and also approach a
concrete definition of "summarization" for our purposes.

The two kinds of HCS's we'll be working with are:

1) the familiar denominations of time (millenia to microseconds etc)
2) our business-specific concept of an "edit", which we'll decompose below.

For our purposes, an "edit" _is_ a file-diff with its associated datetime
(and author which we'll use one day but ignore for now).

Looking at a filediff as an HCS (and bringing some a priori knowledge about
diffs), we can say that an edit HAS MANY chunks, and each chunk has some
sequence (MANY) of line deletes and line adds. We'll call this metric the
"change amount", a term introduced in passing above.

So, looking at a file-diff as an HCS, we could "roll it up" to be just a
"change amount" expressed as some integer (e.g. '47' (being the sum of lines
added and lines removed (or maybe one day we'll sophisticate this a bit))).
Or we could "unroll" it to various levels of detail: like the "change amount"
in each chunk as a list of chunks, or we could unroll it further as a diff
with no lines of context, or we could unroll it further as a unified diff
etc.

Although this is just a mental exercise (we are not going to be rolling-up
and unrolling file-diffs *at runtime* in this facility), it's a good
introduction to our formal treatment of "summarization":

For our purposes

> To summarize is to reduce the amount of space (so the shanon entropy,
  the amount of information) taken up by the surface expression of an
  information tree (as HCS) down to some amount of space that meets some
  criteria (probably that it doesn't exceed some threshold maximum limit
  of space).

Or:

> A summary is a true expression of an information tree that reduces
  the amount of information down to an amount that meets some space constraint.

There is a whole "dimension of concern" missing from this description, though:
the dimension of "general-to-specific". To keep life simple, we'll just frame
it as an axiom:

> When we summarize we swap-in more general expressions for more specific ones.

As it is, this axiomatic definition is perhaps a tautology; because no where
have we defined how you measure this dimensionality of "general vs specific".

For now, we'll just say that more specific expressions "come from" nodes
deeper in the HCS tree, and more general ones come from nodes shallower
in the tree.



# The wedding example

If someone asks you, "How big is the wedding?", a natural response might be
"Oh, hundreds of people. Like, I dunno, 300 people."

But, the optimal answer would depend on context. If it's a wedding planner
asking you the same question, the optimal answer might be "We're inviting
376 people: 310 adults and 66 children."

If you're communicating this same "HCS" tree to the caterer, the answer might
be, "310 adults, 66 children, 10 of those have food allergy X, 10 have food
allergy Y, 3 have both X and Y; 100 of them are vegan" and so on.

But if it's during a casual conversation and someone asks you, "Was it a
big wedding?", an optimal answer might simply be, "Yeah, definitely" or
just "Yes".

The general point is, we can "roll-up" and "drill-down" information in the
same information tree (an HCS) to match different dimensions of focus (i.e.
food requirements vs. "was it big?") and different target amount of expression
space (e.g., just saying "Yes" because it's in the middle of a spirited
conversation you don't want to derail).



## The document history is a chronological sequence of edits

In passing we mentioned but did not explain that the page history (in its
conceptual, ideal, imagined form) is a chronological sequence of events which
(as far as we're concerned) come in two forms of verbs: CREATE and EDIT.

(sidebar: We're not interested in accomodating for giving surface
representation in our page history UI for the event of a document DELETE;
as far as we're concerned if a document is deleted it's as if it never
existed. This makes our treatment of page history "incomplete" but we
are willing to live with this for now in service of KISS.)

To make it more formal, every page history will be of the form:

    CREATE EDIT*

That is, always _one_ CREATE followed by _zero or more_ EDITs.
We won't try to explain _why_ it's this way but we'll offer it as
axiomatic and hopefully self-evident.

(It maybe tempting to conceive of a CREATE as just an EDIT that only adds
line to a formally blank file; indeed this is sort of how it looks when
viewed in the VCS (except the "before" file is `/dev/null`); but A) it's not
technically correct (the best kind of correct) and B) treating CREATE the
same way as EDIT (when we do statistics) would throw the curve way off
because of how much larger the "change amount" is of a typical CREATE
than a typical (non-CREATE) EDIT.)

In the vernacular we may refer to a page history (should we just say
"document history" now?) as a sequence of _EDITS_, but it's always implied
that the document history starts with a CREATE (and whether or not you
consider that a type of EDIT can probably be left as unimportant).



## Summarization strategies for lists of date-times

Lossless compression is probably distinct from summarization, but we'll
shoehorn that transformation into being adject to the class of transformations
we call "summary" because it can help bring the expression towards the same
criteria of reducing the physical space required by the expression.


    edited march 10, 2021
    edited march 11, 2021       ->       edited march 10 & 11, 2021


One way to detect the possibility of this tranformation is "columnar
analysis"; that is, seeing the sentence as a bunch of slots like cells
in a spreadsheet, and looking for two adjacent rows that only vary by
one column, in which case you can combine two sentences into by the
formula hinted at by these examples:

    Jack ate cheese
    Jill ate cheese             ->        Jack & Jill ate cheese

And:

    Jill bought cheese
    Jill ate    cheese          ->        Jill bought & ate cheese

And:

    Jack ate cheese
    Jack ate grapes             ->        Jack ate cheese & grapes

There's even more complicated versions of the formula:

If you insist:

    Jill bought grapes
    Jack ate grapes             ->        Jill bought & Jack ate grapes

But this is an ambiguous compression:

    Jill bought cheese
    Jack ate cheese             ->        Jill & Jack bought & ate cheese


Having suggested all that, we will *not* be using columnar analysis
to achieve this kind of compression for lists of date-times, because
we don't want this awkwardness


    edited march 10, 2020
    edited march 10, 2021      !->       edited march 10, 2020 & 2021


Although it's _technically correct_ it feels unnatural, because:

> Columnar analysis compression shouldn't happen with an HCS unless the
  compression is anchored to the top of the HCS

What?

Imagine instead of this information being tabular that it's represented
internally as an "information tree" that follows a units-of-time-focused HCS:


                          edits that happened
                                     |
                        edits that happend in 2021
                                    /
                        edits that happend in march
                                  /     \
                        edits that       \
                        happend on     edits that
                        the 20th       happened on
                                       the 21st

If you like, we can call this "nested time bucketing".

The really cool thing happens when you imagine each "level" expressing
the information tree with the level of detail it's focused on:

                                   ->  There were edits

      edits that happened          ->  There were 2 edits
                 |
    edits that happend in 2021     ->  There were 2 edits in 2021
                /
    edits that happend in march    ->  There were 2 edits in March, 2021
              /     \
    edits that       \
    happend on     edits that      ->  In 2021, in March there were edits
    the 20th       happened on         on the 20th and the 21st
                   the 21st


We don't explain exactly how we constructed those expressions. (To produce
the expression at the lowest level of detail would indeed take some work.)

But the things to notice here are:

   - Every expression is true (accurate).
   - As you go down to lower levels, the expressions add more information
     but take more space.


Look at this approach on a simpler case of having only one event:

    edits                           ->  Edited
      |
    edits from 2021                 ->  Edited in 2021
      |
    edits from march 2021           ->  Edited in March, 2021
      |
    edits from 10 march 2021        ->  Edited on March 10th, 2021
      |
    edits from the 7pm hour,
    10 march 2021                   ->  Edited around 7pm, March 2021
      |
    edits from the 38th minute of
    the 20th hour of march 10, 2021 ->  Edited March 10, 2021 at 7:37PM

The thing to notice is, even though this "tree" has only one business
item in it, still it produces the useful tranformation of summarizing.



# A fun complication: bucketing EDIT events into "change amount" buckets

We're going to want to categorize every edit into one of several
"change amount categories". Change amount categories are a bit like
weight-classes in say, boxing (lightweight, welterweight, etc) But:

  - The number of change amount categories will be a parameter given by
    the human before the initial big indexing pass. It should *not* be
    a fixed number we hard-code around (but that said it will
    probably be 2).
  - We want the boundaries of the change amount categories to be derived
    from the statistical data gathered in the initial pass.


Ignoring the "how", the "what" to know is that

> Edits should be grouped by change amount category,
  but only when they are contiguous.

So, yes:

    Minor edits in March and April. Major edit in May.

But not:

    Minor edits in January, February and April. Major edit in March.

Yes:

    Minor edits in January and February. Major edit in February.

Also this can happen, somehow:

    In 2021, 2 minor and 1 major edit.

And of course:

    3 edits in 2021.



# (EDIT)

(EDIT: what we ended up doing was something like:

- hard-coding time-bucket sizes changes to certain fixed points N amount of
  time ago (something like 2 days then three months)
- then pruning the "context stacks" of detail around those time buckets
  (if it's between two days and three months old, we don't care about
  time of day or below, etc.)
- then grouping by (chunking to) context stack value
  (e.g. all edits from the 4pm hour into one table, etc)
- then summarizing each group into a count summaries (e.g "4 edits on this day")
- THEN (the interesting thing) when traversing this final collection, we
  don't need to re-introduce root-anchored same contexts (e.g., if it's
  "2021 march" then "2021 april" we don't need to re-introdue 2021).
)



# THE DATA GATHERING ALGORITHM

For the proof-of-concept, the objective is to produce a chronological list of
"edits" per "document"; where each edit somehow indicates "how much change"
(as well as the datetime of the edit and probably the single associated SHA).

The dream for kiss-rdb (born 26 months prior to writing) has always been to
leverage existing VCS and existing plain-old files to exhibit higher-level
CMS-type features, like audit logs. Today we reify this dream.

At writing, pho can produce a document from two differnt kinds of backend
sources: 1) through notecards and 2) as an existing filesystem file that
has been "rigged" to look like it's just any other single notecard (but with
a lot of content in it for one notecard).

Generating a list of edits per-document will be more difficult for
notecard-based documents than for rigged, file-based documents, so we're
frontloading the harder way first (because it will take less work in the end,
doing an easy task with strong tools rather than doing a difficult task with
weak tools and then needing to go back and revise the weak tools which might
break how we do the easier work).

As we write this, as we think of how generating an edit-history per document
will be derived from generating an edit-history per entity, we realise that
that's a "kiss-rdb" thing, to generate such a history, rather than a pho
thing. So we'll jump over there and see you back over here once we've
written that.



[1]: https://en.wikipedia.org/wiki/Help:Page_history

# (document-meta)

  - #born
